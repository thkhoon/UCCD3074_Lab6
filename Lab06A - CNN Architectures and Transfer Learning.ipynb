{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hyqpElym-dXl"
   },
   "source": [
    "# Lab 6A: CNN Architectures and Transfer Learning\n",
    "\n",
    "The learning objectives for this lab exercise are as follows:\n",
    "1. Customize the standard CNN Network to a targeted task\n",
    "2. Perform different kinds of transfer learning:\n",
    "    1. Train from scratch\n",
    "    2. Finetune the whole model\n",
    "    3. Finetune the upper layers of the model\n",
    "    4. As a feature extractor\n",
    "\n",
    "In practice, it is common to use a **standard CNN architectures** such that ResNet, MNASNet, ResNeXt, EfficientNet, etc. to build a model. The effectiveness of these network architectures has been well attested for a wide range of applications. \n",
    "\n",
    "Rather than training from scratch, it is advisable to use **transfer learning** by training on top of a standard model that has been **pretrained** on the ImageNet dataset. Transfer learning reduces overfitting and improves the generalization performance of the trained model, especially when the training set for the targeted task is small. The [`torchvision.models`](https://pytorch.org/vision/stable/models.html) package contains these different network models that have been pre-trained on ImageNet. \n",
    "\n",
    "We perform transfer learning in two ways:\n",
    "\n",
    "1. *Finetuning the convnet*: Instead of random initialization,  initialize the network with the pretrained network. \n",
    "\n",
    "2. *Fixed feature extractor*: Freeze the weights for all of the layers of the network except for the final fully connected (fc) layer. Replace the last fc layer so that the output size is the same as the number of classes for the new task. The new layer is initialized with random weights and only this layer is trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2KWVeVT-dXv"
   },
   "source": [
    "Mount google drive onto virtual machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0wMiAU9V-dX2"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5eMY7gG-dYC"
   },
   "source": [
    "Change current directory to Lab 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWdhHmts-dYF"
   },
   "outputs": [],
   "source": [
    "cd \"/content/gdrive/My Drive/UCCD3074_Labs/UCCD3074_Lab6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMc8XRwD-dYT"
   },
   "source": [
    "Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NgG6mM_c-dYY"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch, torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "\n",
    "from cifar10 import CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23H6bUc4-dY5"
   },
   "source": [
    "---\n",
    "## Helper Functions\n",
    "\n",
    "Define the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0G9F-olF-dY8"
   },
   "outputs": [],
   "source": [
    "loss_iter = 1\n",
    "\n",
    "def train(net, num_epochs, lr=0.1, momentum=0.9, verbose=True):\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    loss_iterations = int(np.ceil(len(trainloader)/loss_iter))\n",
    "    \n",
    "    # transfer model to GPU\n",
    "    if torch.cuda.is_available():\n",
    "        net = net.cuda()\n",
    "    \n",
    "    # set the optimizer\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
    "    \n",
    "    # set to training mode\n",
    "    net.train()\n",
    "\n",
    "    # train the network\n",
    "    for e in range(num_epochs):    \n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_count = 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "\n",
    "            # Clear all the gradient to 0\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # transfer data to GPU\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # forward propagation to get h\n",
    "            outs = net(inputs)\n",
    "\n",
    "            # compute loss \n",
    "            loss = F.cross_entropy(outs, labels)\n",
    "\n",
    "            # backpropagation to get dw\n",
    "            loss.backward()\n",
    "\n",
    "            # update w\n",
    "            optimizer.step()\n",
    "\n",
    "            # get the loss\n",
    "            running_loss += loss.item()\n",
    "            running_count += 1\n",
    "\n",
    "             # display the averaged loss value \n",
    "            if i % loss_iterations == loss_iterations-1 or i == len(trainloader) - 1:                \n",
    "                train_loss = running_loss / running_count\n",
    "                running_loss = 0. \n",
    "                running_count = 0.\n",
    "                if verbose:\n",
    "                    print(f'[Epoch {e+1:2d}/{num_epochs:d} Iter {i+1:5d}/{len(trainloader)}]: train_loss = {train_loss:.4f}')       \n",
    "                \n",
    "                history.append(train_loss)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljSQ0NXh-dZD"
   },
   "source": [
    "Define the evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBvtq0t3-dZG"
   },
   "outputs": [],
   "source": [
    "def evaluate(net):\n",
    "    # set to evaluation mode\n",
    "    net.eval()\n",
    "    \n",
    "    # running_correct\n",
    "    running_corrects = 0\n",
    "    \n",
    "    for inputs, targets in testloader:\n",
    "        \n",
    "        # transfer to the GPU\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "        \n",
    "        # perform prediction (no need to compute gradient)\n",
    "        with torch.no_grad():\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            running_corrects += (targets == predicted).double().sum()\n",
    "            \n",
    "    print('Accuracy = {:.2f}%'.format(100*running_corrects/len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ws7qs6tr-dZM"
   },
   "source": [
    "## 1. Load CIFAR10 dataset\n",
    "\n",
    "Here, we use a sub-sample of CIFAR10 where we use a sub-sample of 1000 training and testing samples. The sample size is small and hence is expected to face overfitting issue. Using a pretrained model alleviates the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1eqihDIp-dZO"
   },
   "outputs": [],
   "source": [
    "# transform the model\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# dataset\n",
    "trainset = CIFAR10(train=True, download=True, transform=transform, num_samples=1000)\n",
    "testset  = CIFAR10(train=False, download=True, transform=transform, num_samples=1000)\n",
    "\n",
    "# dataloader]\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
    "testloader  = DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNm3qtT0-dZS"
   },
   "source": [
    "## 2. The ResNet50 model\n",
    "\n",
    "In this section, we shall build our network using a standard network architectures. We customize a pre-trained [ResNet50](https://pytorch.org/vision/stable/models/generated/torchvision.models.resnet50.html#resnet50) by replacing its classifier layer, i.e., the last fully connected layer with our own. The original ImageNet classifier is designed to classify 1000 output classes whereas our CIFAR10 classifier handles only 10 classes. \n",
    "\n",
    "### Using the pre-trained models\n",
    "\n",
    "First, let's learn how to load and use a pre-trained model as it is. The following table lists the pretrained models for ResNet50 together their reported accurcies on ImageNet-1K with single crops.\n",
    "\n",
    "|**weight**|**Acc@1**|**Acc@5**|**Params**|\n",
    "|:---:|:---:|:---:|:---:|\n",
    "|ResNet50_Weights.IMAGENET1K_V1|76.13|92.862|25.6MB|\n",
    "|ResNet50_Weights.IMAGENET1K_V2|80.858|95.434|25.6MB|\n",
    "\n",
    "where IMAGENET1K_V2 improves upon IMAGENET1K_V1 by using a new [training recipe](https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoBVYgUyP6QM"
   },
   "source": [
    "To specify the pretrained model, you can use the predefined constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iegSJvm5M8Ty"
   },
   "outputs": [],
   "source": [
    "# ... import required module ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JVkKmuqcWfDS"
   },
   "outputs": [],
   "source": [
    "# ... load pretrained resnet18 model with predefined constant argument ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyG1kb7EP44o"
   },
   "source": [
    "or a string argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYI9FrywPL-s"
   },
   "outputs": [],
   "source": [
    "# ... load pretrained resnet18 model with string argument ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79wcOsOZObDC"
   },
   "source": [
    "### Inferencing with the pretrained model\n",
    "\n",
    "Some pretrained model needs specific preprocessing steps (e.g., resize into a specific resolution / rescale the values, etc.). The preprocessing steps vary depending on how the model was trained. The necessary information for inference transforms are provided on the weight documentation. But to simplify inference, `TorchVision` also bundle a `transform` utility into `ResNet.Weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5fKx4JcQ0mI"
   },
   "outputs": [],
   "source": [
    "# ... load the preprocess function ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0LHr6uqRten"
   },
   "outputs": [],
   "source": [
    "# ... read image ...\n",
    "\n",
    "# ... preprocess image ...\n",
    "\n",
    "# ... create the batch dimension ...\n",
    "\n",
    "print('Shape of x after unsqueezing:', x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRxAm0w7VG44"
   },
   "source": [
    "Perform inference with the pretrained model. The classes of the pretrained model can be found at `weights.meta['categories']`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLTn5qeFU90g"
   },
   "outputs": [],
   "source": [
    "# ... perform inference\n",
    "\n",
    "# ... get predicted class ...\n",
    "\n",
    "# ... print predicted class label ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kDePxTL7kgV"
   },
   "source": [
    "\n",
    "### Customizing ResNet50\n",
    "\n",
    "In the following, we shall replace the last layer with a new classifier layer. The pre-trained model is designed to classify ImageNet's 1000 image categories. In the following, we shall customize it to classify Cifar10's 10 classes. First, let's look at how ResNet50 is implemented in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cCT1cjPD-dZb"
   },
   "outputs": [],
   "source": [
    "# ... print network ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CrWZSU_xHLRg"
   },
   "outputs": [],
   "source": [
    "# ... print the children of network ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JVfe784-dZk"
   },
   "source": [
    "Here are some observations:\n",
    "* `conv1`, `bn1`, `relu` and `maxpool` are the *stem* network\n",
    "* There are 4 *blocks* in the network, namely `layer1`, `layer2`, `layer3` and `layer4`.\n",
    "* Each of the block contains two convolutional layers. \n",
    "* The second last layer (`avgpool`) performs *global average pooling* to average out the spatial dimensions. \n",
    "* The last layer (`fc`) is a linear layer that functions as a classifier. **This is the layer that we want to replace to fit our model**.\n",
    "\n",
    "To customize the network, we need to replace the `fc` layer with our own classifier layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJLn-l4C-dZl"
   },
   "outputs": [],
   "source": [
    "def build_network(weights=None):\n",
    "    # ... customize the resnet18 network for CIFAR 10\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ0QEzwX-dZr"
   },
   "source": [
    "Let's visualize what we have built. Note that the last layer of the network (`fc`) now has 10 instead of 1000 neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H83zW0QF-dZs",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(build_network())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j76AmVMR-dZ0"
   },
   "source": [
    "---\n",
    "### Model 1: Training from scratch\n",
    "\n",
    "Let's build the network **without** loading the pretrained model. To do this, we set `weights=None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s1bzb0AF-dZ1"
   },
   "outputs": [],
   "source": [
    "# ... build network without pretraining ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ke4oRDBD-dZ4"
   },
   "source": [
    "Train the model and save the training loss history into `history1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ozXEDbIU-dZ6"
   },
   "outputs": [],
   "source": [
    "history1 = train(net1, num_epochs=30, lr=0.01, momentum=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYgMvo78-daA"
   },
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BZUzQ3LO-daB"
   },
   "outputs": [],
   "source": [
    "evaluate(net1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoCFbpik-daG"
   },
   "source": [
    "---\n",
    "### Model 2: Finetuning the pretrained model\n",
    "\n",
    "Typically, a standard network come with a pretrained model trained on ImageNet's large-scale dataset for the image classification task. \n",
    "* In the following, we shall load resnet50 with the pretrained model and use it to **initialize** the network.  To do this, we set `pretrained=True`.\n",
    "* The training will update the parameters **all layers** of the network.\n",
    "\n",
    "For Windows system, the pretrained model will be saved to the following directory: `C:\\Users\\<user name>\\.cache\\torch\\checkpoints`. A PyTorch model has an extension of `.pt` or `.pth`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4OgAOih-daH"
   },
   "outputs": [],
   "source": [
    "# ... build network with IMAGENET1K_V2 pretrained model ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fZn_3_X-dac"
   },
   "source": [
    "By default, all the layers are set to `requires_grad=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z57XPXtt-dad"
   },
   "outputs": [],
   "source": [
    "# ... display the requires_grad for all layers ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2WCRuqTd-daM"
   },
   "source": [
    "Train the model and save into `history2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MxNWP06d-daN"
   },
   "outputs": [],
   "source": [
    "history2 = train(net2, num_epochs=30, lr=0.01, momentum=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZN6nYHR-daQ"
   },
   "source": [
    "Evaluate the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qjkHZEfx-daR"
   },
   "outputs": [],
   "source": [
    "evaluate(net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNU2oW6n-daV"
   },
   "source": [
    "---\n",
    "### Model 3: As a fixed feature extractor\n",
    "\n",
    "When the dataset is too small, fine-tuning the model may still incur overfitting. In this case, you may want to try to use the pretrained as a fixed feature extractor where we train only the  classifier layer (i.e., **last layer**) that we have newly inserted into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4E9-Smri-daX"
   },
   "outputs": [],
   "source": [
    "# ... build network with IMAGENET1K_V2 pretrained model ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGZpQHKM-dag"
   },
   "source": [
    "We set `requires_grad=False` for all parameters except for the newly replaced layer `fc`, i.e., the last two parameters in `resnet.parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-9dSPUW-dag"
   },
   "outputs": [],
   "source": [
    "# ... set requires grad to FALSE for all parameters except for the newly replace layer ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdA2balW-daj"
   },
   "outputs": [],
   "source": [
    "# ... confirm that the gradients have been set correctly ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5tAEgqj-dam"
   },
   "source": [
    "Train the model and save into `history3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "upS5DzLI-dao"
   },
   "outputs": [],
   "source": [
    "history3 = train(net3, num_epochs=30, lr=0.01, momentum=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHbWS81I-dav"
   },
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wEd3pB8J-day"
   },
   "outputs": [],
   "source": [
    "evaluate(net3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjwhSdAa-da1"
   },
   "source": [
    "---\n",
    "### Model 4: Finetuning the top few layers\n",
    "\n",
    "We can also tune the top few layers of the network. The following tunes all the layers in the block `layer 4` as well as the `fc` layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K9pDdnsf-da2"
   },
   "outputs": [],
   "source": [
    "# ... build network with IMAGENET1K_V2 pretrained model ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nejPZBc1-da5"
   },
   "source": [
    "Then, we freeze all tha layers except for `layer4` and `fc` layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VfolcT6O-da6"
   },
   "outputs": [],
   "source": [
    "# ... set requires grad to FALSE for all parameters except for layer4 and fc layers ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CNGLTmQ-dbB"
   },
   "outputs": [],
   "source": [
    "# ... confirm that the gradients have been set correctly ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyR4vKxz-dbH"
   },
   "source": [
    "Train the model and save into `history4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DGIpDEO6-dbI"
   },
   "outputs": [],
   "source": [
    "history4 = train(net4, num_epochs=30, lr=0.01, momentum=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "428Jjhmi-dbM"
   },
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdLliUfd-dbO"
   },
   "outputs": [],
   "source": [
    "evaluate(net4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlIhET9P-dbR"
   },
   "source": [
    "### Plotting training loss\n",
    "\n",
    "Lastly, we plot the training loss history for each of the training schemes above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l0Nq76zy-dbR"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history1, label='From scratch')\n",
    "plt.plot(history2, label='Finetuning the pretrained model')\n",
    "plt.plot(history3, label='As a fixed extractor')\n",
    "plt.plot(history4, label='Finetuning the top few layers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZIKznqu-dbU"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "You can try with different network architectures (e.g., [EfficientNet-B0](https://pytorch.org/vision/stable/models/efficientnet.html)) and see if it results in higher test accuracy.\n",
    "\n",
    "> *The list of all pre-trained models in PyTorch is listed in this [Table](https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights).*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pt1ejRGJEMvx"
   },
   "outputs": [],
   "source": [
    "def build_network(weights='IMAGENET1K_V1'):\n",
    "    # ... your answer here ...\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lr6hiyxqE7wH"
   },
   "outputs": [],
   "source": [
    "efficientNet = build_network() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSX7XDHzFyn0"
   },
   "outputs": [],
   "source": [
    "history5 = train(efficientNet, num_epochs=30, lr=0.01, momentum=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8aKz3u9F2L9"
   },
   "outputs": [],
   "source": [
    "evaluate(efficientNet)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab06A - CNN Architectures and Transfer Learning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

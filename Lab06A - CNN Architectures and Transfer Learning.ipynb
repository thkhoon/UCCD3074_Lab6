{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Lab06A - CNN Architectures and Transfer Learning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hyqpElym-dXl"},"source":["# Lab 6A: CNN Architectures and Transfer Learning\n","\n","The learning objectives for this lab exercise are as follows:\n","1. Customize the standard CNN Network to a targeted task\n","2. Perform different kinds of transfer learning:\n","    1. Train from scratch\n","    2. Finetune the whole model\n","    3. Finetune the upper layers of the model\n","    4. As a feature extractor\n","\n","In practice, it is common to use a **standard CNN architectures** such that ResNet, MNASNet, ResNeXt, EfficientNet, etc. to build a model. The effectiveness of these network architectures has been well attested for a wide range of applications. The [`torchvision.models`](https://pytorch.org/vision/stable/models.html) subpackage contains these different network models that have been pre-trained on ImageNet. Rather than training from scratch, it is advisable to use **transfer learning** by training on top of a standard model that has been **pretrained** on the ImageNet dataset. Transfer learning reduces overfitting and improves the generalization performance of the trained model, especially when the training set for the targeted task is small. We perform transfer learning in two ways:\n","\n","1. *Finetuning the convnet*: Instead of random initialization,  initialize the network with the pretrained network. \n","\n","2. *Fixed feature extractor*: Freeze the weights for all of the layers of the network except for the final fully connected (fc) layer. Replace the last fc layer so that the output size is the same as the number of classes for the new task. The new layer is initialized with random weights and only this layer is trained.\n","\n","> Training a deep architecture using a pre-trained model allows us to train on a small dataset with less overfitting."]},{"cell_type":"markdown","metadata":{"id":"k2KWVeVT-dXv"},"source":["Mount google drive onto virtual machine"]},{"cell_type":"code","metadata":{"id":"0wMiAU9V-dX2"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y5eMY7gG-dYC"},"source":["Change current directory to Lab 6"]},{"cell_type":"code","metadata":{"id":"jWdhHmts-dYF"},"source":["cd \"/content/gdrive/My Drive/UCCD3074_Labs/UCCD3074_Lab6\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nMc8XRwD-dYT"},"source":["Load required libraries"]},{"cell_type":"code","metadata":{"id":"NgG6mM_c-dYY"},"source":["import numpy as np\n","import torchvision.models as models\n","\n","import torch, torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","import torchvision.transforms as transforms\n","from torchsummary import summary\n","\n","from cifar10 import CIFAR10"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23H6bUc4-dY5"},"source":["---\n","## Helper Functions\n","\n","Define the train function"]},{"cell_type":"code","metadata":{"id":"0G9F-olF-dY8"},"source":["loss_iter = 1\n","\n","def train(net, num_epochs, lr=0.1, momentum=0.9, verbose=True):\n","    \n","    history = []\n","    \n","    loss_iterations = int(np.ceil(len(trainloader)/loss_iter))\n","    \n","    # transfer model to GPU\n","    if torch.cuda.is_available():\n","        net = net.cuda()\n","    \n","    # set the optimizer\n","    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n","    \n","    # set to training mode\n","    net.train()\n","\n","    # train the network\n","    for e in range(num_epochs):    \n","\n","        running_loss = 0.0\n","        running_count = 0.0\n","\n","        for i, (inputs, labels) in enumerate(trainloader):\n","\n","            # Clear all the gradient to 0\n","            optimizer.zero_grad()\n","\n","            # transfer data to GPU\n","            if torch.cuda.is_available():\n","                inputs = inputs.cuda()\n","                labels = labels.cuda()\n","\n","            # forward propagation to get h\n","            outs = net(inputs)\n","\n","            # compute loss \n","            loss = F.cross_entropy(outs, labels)\n","\n","            # backpropagation to get dw\n","            loss.backward()\n","\n","            # update w\n","            optimizer.step()\n","\n","            # get the loss\n","            running_loss += loss.item()\n","            running_count += 1\n","\n","             # display the averaged loss value \n","            if i % loss_iterations == loss_iterations-1 or i == len(trainloader) - 1:                \n","                train_loss = running_loss / running_count\n","                running_loss = 0. \n","                running_count = 0.\n","                if verbose:\n","                    print(f'[Epoch {e+1:2d}/{num_epochs:d} Iter {i+1:5d}/{len(trainloader)}]: train_loss = {train_loss:.4f}')       \n","                \n","                history.append(train_loss)\n","    \n","    return history"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ljSQ0NXh-dZD"},"source":["Define the evaluate function"]},{"cell_type":"code","metadata":{"id":"iBvtq0t3-dZG"},"source":["def evaluate(net):\n","    # set to evaluation mode\n","    net.eval()\n","    \n","    # running_correct\n","    running_corrects = 0\n","    \n","    for inputs, targets in testloader:\n","        \n","        # transfer to the GPU\n","        if torch.cuda.is_available():\n","            inputs = inputs.cuda()\n","            targets = targets.cuda()\n","        \n","        # perform prediction (no need to compute gradient)\n","        with torch.no_grad():\n","            outputs = net(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","            running_corrects += (targets == predicted).double().sum()\n","            \n","    print('Accuracy = {:.2f}%'.format(100*running_corrects/len(testloader.dataset)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ws7qs6tr-dZM"},"source":["## 1. Load CIFAR10 dataset\n","\n","Here, we use a sub-sample of CIFAR10 where we use a sub-sample of 1000 training and testing samples. The sample size is small and hence is expected to face overfitting issue. Using a pretrained model alleviates the problem."]},{"cell_type":"code","metadata":{"id":"1eqihDIp-dZO"},"source":["# transform the model\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.RandomCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# dataset\n","trainset = CIFAR10(train=True, download=True, transform=transform, num_samples=1000)\n","testset  = CIFAR10(train=False, download=True, transform=transform, num_samples=1000)\n","\n","# dataloader]\n","trainloader = DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n","testloader  = DataLoader(testset, batch_size=128, shuffle=True, num_workers=2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XNm3qtT0-dZS"},"source":["## 2. The ResNet18 model\n","\n","In this section, we shall build our network using a standard network architectures. We customize resnet18 by replacing its classifier layer, i.e., the last fully connected layer with our own. The original classifier layer has 1000 outputs (ImageNet has 1000 output classes) whereas our model has only 10. \n","\n","### Network Architecture of ResNet18\n","\n","We shall use resnet18 as our base network. Before we customize it, let's print out the summary of all layers of the model to view its architecture. Bear in mind that to customize the network, we need to replace the last linear layer. \n","\n","First, let's review the resnet18 network architecture."]},{"cell_type":"code","metadata":{"id":"JVkKmuqcWfDS"},"source":["# ... create resnet18 ..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFTM70NnWgy_"},"source":["# ... print network ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We can get the name of the first layer by accessing the `.named_children`."],"metadata":{"id":"_kDePxTL7kgV"}},{"cell_type":"code","metadata":{"id":"cCT1cjPD-dZb"},"source":["# ... display the name of first layer ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4JVfe784-dZk"},"source":["We will see that:\n","* `layer1` to `layer4` contains two blocks each. Each block is contains two convolutional layers. \n","* The second last layer (`avgpool`) performs *global average pooling* to average out the spatial dimensions. \n","* The last layer (`fc`) is a linear layer and indeed, it functions as a classifier. This is the layer that we want to replace to fit our model.\n","\n","To customize the network, we need to replace the `fc` layer with our own classifier layer.\n","\n","### Customizing ResNet18\n","\n","In the following, we shall replace the last layer with a new classifier layer. The original layer  is designed to classify ImageNet's 1000 image categories. The new layers will be used to classify Cifar10's 10 classes"]},{"cell_type":"code","metadata":{"id":"qJLn-l4C-dZl"},"source":["# ... create build_network ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LZ0QEzwX-dZr"},"source":["Let's visualize what we have built. Note that the last layer of the network (`fc`) now has 10 instead of 1000 neurons."]},{"cell_type":"code","metadata":{"id":"H83zW0QF-dZs","scrolled":false},"source":["print(build_network())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j76AmVMR-dZ0"},"source":["---\n","### Model 1: Training from scratch\n","\n","Let's build the network **without** loading the pretrained model. To do this, we set `pretrained=False`."]},{"cell_type":"code","metadata":{"id":"s1bzb0AF-dZ1"},"source":["# ... load the model without pretraining..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ke4oRDBD-dZ4"},"source":["Train the model and save the training loss history into `history1`."]},{"cell_type":"code","metadata":{"id":"ozXEDbIU-dZ6"},"source":["history1 = train(resnet18, num_epochs=30, lr=0.01, momentum=0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hYgMvo78-daA"},"source":["Evaluate the model"]},{"cell_type":"code","metadata":{"id":"BZUzQ3LO-daB"},"source":["evaluate(resnet18)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VoCFbpik-daG"},"source":["---\n","### Model 2: Finetuning the pretrained model\n","\n","Typically, a standard network come with a pretrained model trained on ImageNet's large-scale dataset for the image classification task. \n","* In the following, we shall load resnet18 with the pretrained model and use it to **initialize** the network.  To do this, we set `pretrained=True`.\n","* The training will update the parameters **all layers** of the network.\n","\n","For Windows system, the pretrained model will be saved to the following directory: `C:\\Users\\<user name>\\.cache\\torch\\checkpoints`. A PyTorch model has an extension of `.pt` or `.pth`. "]},{"cell_type":"code","metadata":{"id":"L4OgAOih-daH"},"source":["# ... load the pretrained model ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3fZn_3_X-dac"},"source":["By default, all the layers are set to `requires_grad=True`"]},{"cell_type":"code","metadata":{"id":"Z57XPXtt-dad"},"source":["# ... Unfreeze all layers ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2WCRuqTd-daM"},"source":["Train the model and save into `history2`."]},{"cell_type":"code","metadata":{"id":"MxNWP06d-daN"},"source":["history2 = train(resnet18, num_epochs=30, lr=0.01, momentum=0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WZN6nYHR-daQ"},"source":["Evaluate the network"]},{"cell_type":"code","metadata":{"id":"qjkHZEfx-daR"},"source":["evaluate(resnet18)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bNU2oW6n-daV"},"source":["---\n","### Model 3: As a fixed feature extractor\n","\n","When the dataset is too small, fine-tuning the model may still incur overfitting. In this case, you may want to try to use the pretrained as a fixed feature extractor where we train only the  classifier layer (i.e., **last layer**) that we have newly inserted into the network."]},{"cell_type":"code","metadata":{"id":"4E9-Smri-daX"},"source":["# ... load the pretrained model ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pGZpQHKM-dag"},"source":["We set `requires_grad=False` for all parameters except for the newly replaced layer `fc`, i.e., the last two parameters in `resnet.parameters()`."]},{"cell_type":"code","metadata":{"id":"5-9dSPUW-dag"},"source":["# ... freeze all layers ..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rdA2balW-daj"},"source":["# ... check that all layers are freezed ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X5tAEgqj-dam"},"source":["Train the model and save into `history3`."]},{"cell_type":"code","metadata":{"id":"upS5DzLI-dao"},"source":["history3 = train(resnet18, num_epochs=30, lr=0.01, momentum=0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GHbWS81I-dav"},"source":["Evaluate the model"]},{"cell_type":"code","metadata":{"id":"wEd3pB8J-day"},"source":["evaluate(resnet18)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PjwhSdAa-da1"},"source":["---\n","### Model 4: Finetuning the top few layers\n","\n","We can also tune the top few layers of the network. The following tunes all the layers in the block `layer 4` as well as the `fc` layer.\n"]},{"cell_type":"code","metadata":{"id":"K9pDdnsf-da2"},"source":["# ... load the pretrained model ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nejPZBc1-da5"},"source":["Then, we freeze all tha layers except for `layer4` and `fc` layers"]},{"cell_type":"code","metadata":{"id":"VfolcT6O-da6"},"source":["# ... freeze the bottom few layers ..."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CNGLTmQ-dbB"},"source":["# ... check that only the selected layers are freezed ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XyR4vKxz-dbH"},"source":["Train the model and save into `history4`."]},{"cell_type":"code","metadata":{"id":"DGIpDEO6-dbI"},"source":["history4 = train(resnet18, num_epochs=30, lr=0.01, momentum=0.8)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"428Jjhmi-dbM"},"source":["Evaluate the model"]},{"cell_type":"code","metadata":{"id":"JdLliUfd-dbO"},"source":["evaluate(resnet18)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FlIhET9P-dbR"},"source":["### Plotting training loss\n","\n","Lastly, we plot the training loss history for each of the training schemes above."]},{"cell_type":"code","metadata":{"id":"l0Nq76zy-dbR"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(history1, label='From scratch')\n","plt.plot(history2, label='Finetuning the pretrained model')\n","plt.plot(history3, label='As a fixed extractor')\n","plt.plot(history4, label='Finetuning the top few layers')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Exercise\n","\n","You can try with different network architectures (e.g., EfficientNet-B0) and see if it results in higher test accuracy."],"metadata":{"id":"kwsxNZ7xKnKE"}},{"cell_type":"code","source":["def build_network(pretrained=True):\n","    # ...\n","    return efficientNet"],"metadata":{"id":"BOcC-X1iKn9v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["efficientNet = build_network() "],"metadata":{"id":"8UParU9jK2He"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history5 = train(efficientNet, num_epochs=30, lr=0.01, momentum=0.8)"],"metadata":{"id":"l3XtxIsmK4bF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["evaluate(efficientNet)"],"metadata":{"id":"8U9ZIEbNK5Ei"},"execution_count":null,"outputs":[]}]}